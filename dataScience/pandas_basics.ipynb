{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = {'name': pd.Series(['Braund', 'Cumings', 'Heikkinen', 'Allen'], index=['a', 'b', 'c', 'd']),\n",
    "    'age': pd.Series([22, 38, 26, 35], index=['a', 'b', 'c', 'd']),\n",
    "    'fare': pd.Series([7.25, 71.83, 8.05], index=['a', 'b', 'd']),\n",
    "    'survived?': pd.Series([False, True, True, False], index=['a', 'b', 'c', 'd'])}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['name', 'age']] # Show selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'] # Show selected column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name # A shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['a']  # Show selected row in a column form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['age'] >= 30]  # Show only rows that comply with a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['survived?'][df['age'] >= 30] # Show only rows from a selected column that comply with a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(['Braund', 'Cumings', 'Heikkinen', 'Allen'], index=['a', 'b', 'c', 'd'])\n",
    "series['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # 5 first rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() # 5 last rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[['a']]  # Select by location based indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[0]] # Select by integer-location based indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.age > 30) & (df.fare < 10)] # Filter with multiple conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df[['age', 'fare']].apply(np.mean)  # Apply a function to selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.map(lambda x: x >= 25)   # Map if a condition is met "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.applymap(lambda x: x>= 25) # Map if a condition is met to whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuteness = pd.Series([1, 2, 3, 4, 5], index=['Cockroach', 'Fish', 'Mini Pig',\n",
    "                                                 'Puppy', 'Kitten'])\n",
    "print(cuteness > 3)\n",
    "print(\"\")\n",
    "print(cuteness[cuteness > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series\n",
    "\n",
    "def create_dataframe():\n",
    "    countries = ['Russian Fed.', 'Norway', 'Canada', 'United States',\n",
    "                 'Netherlands', 'Germany', 'Switzerland', 'Belarus',\n",
    "                 'Austria', 'France', 'Poland', 'China', 'Korea', \n",
    "                 'Sweden', 'Czech Republic', 'Slovenia', 'Japan',\n",
    "                 'Finland', 'Great Britain', 'Ukraine', 'Slovakia',\n",
    "                 'Italy', 'Latvia', 'Australia', 'Croatia', 'Kazakhstan']\n",
    "\n",
    "    gold = [13, 11, 10, 9, 8, 8, 6, 5, 4, 4, 4, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "    silver = [11, 5, 10, 7, 7, 6, 3, 0, 8, 4, 1, 4, 3, 7, 4, 2, 4, 3, 1, 0, 0, 2, 2, 2, 1, 0]\n",
    "    bronze = [9, 10, 5, 12, 9, 5, 2, 1, 5, 7, 1, 2, 2, 6, 2, 4, 3, 1, 2, 1, 0, 6, 2, 1, 0, 1]\n",
    "    \n",
    "    df = {'countries': Series(countries), 'gold': Series(gold), \n",
    "          'silver': Series(silver), 'bronze': Series(bronze)}\n",
    "    \n",
    "    # No need to use pd.Series:\n",
    "    # df = {'countries': countries, 'gold': gold, \n",
    "    #      'silver': silver, 'bronze': bronze}\n",
    "          \n",
    "    olympic_medal_counts_df = DataFrame(df)\n",
    "    \n",
    "    return olympic_medal_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = create_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "def points():\n",
    " \n",
    "\n",
    "    countries = ['Russian Fed.', 'Norway', 'Canada', 'United States',\n",
    "                 'Netherlands', 'Germany', 'Switzerland', 'Belarus',\n",
    "                 'Austria', 'France', 'Poland', 'China', 'Korea', \n",
    "                 'Sweden', 'Czech Republic', 'Slovenia', 'Japan',\n",
    "                 'Finland', 'Great Britain', 'Ukraine', 'Slovakia',\n",
    "                 'Italy', 'Latvia', 'Australia', 'Croatia', 'Kazakhstan']\n",
    "\n",
    "    gold = [13, 11, 10, 9, 8, 8, 6, 5, 4, 4, 4, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "    silver = [11, 5, 10, 7, 7, 6, 3, 0, 8, 4, 1, 4, 3, 7, 4, 2, 4, 3, 1, 0, 0, 2, 2, 2, 1, 0]\n",
    "    bronze = [9, 10, 5, 12, 9, 5, 2, 1, 5, 7, 1, 2, 2, 6, 2, 4, 3, 1, 2, 1, 0, 6, 2, 1, 0, 1]\n",
    " \n",
    "    data = {'country_name': countries, 'gold': gold, 'silver': silver, 'bronze': bronze}\n",
    "    df = DataFrame(data)\n",
    "    \n",
    "    df['points'] = df[['gold', 'silver', 'bronze']].dot([4, 2, 1])\n",
    "  \n",
    "    olympic_points_df = df[['country_name', 'points']]\n",
    "    \n",
    "    return olympic_points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_data = pandas.read_csv('master.csv')\n",
    "baseball_data['height_plus_weight'] = baseball_data['height'] + baseball_data['weight']  # Create new columns\n",
    "baseball_data.to_csv('baseball_data_with_weight_height.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql\n",
    "import pandas as pd\n",
    "\n",
    "# path = 'https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/aadhaar_data.csv'\n",
    "def select_first_50(filename):\n",
    "    aadhaar_data = pd.read_csv(filename)\n",
    "    aadhaar_data.rename(columns = lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "    \n",
    "    q = '''\n",
    "    SELECT gender, district, sum(aadhaar_generated) FROM aadhaar_data WHERE age>50 GROUP BY gender, district\n",
    "    '''\n",
    "    \n",
    "    solution = pandasql.sqldf(q.lower(), locals())\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_first_50('aadhaar_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "def aggregate_query(filename):\n",
    "    # Read in our aadhaar_data csv to a pandas dataframe.  Afterwards, we rename the columns\n",
    "    # by replacing spaces with underscores and setting all characters to lowercase, so the\n",
    "    # column names more closely resemble columns names one might find in a table.\n",
    "    \n",
    "    aadhaar_data = pandas.read_csv(filename)\n",
    "    aadhaar_data.rename(columns = lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "\n",
    "    # Write a query that will select from the aadhaar_data table how many men and how \n",
    "    # many women over the age of 50 have had aadhaar generated for them in each district.\n",
    "    # aadhaar_generated is a column in the Aadhaar Data that denotes the number who have had\n",
    "    # aadhaar generated in each row of the table.\n",
    "    #\n",
    "    # Note that in this quiz, the SQL query keywords are case sensitive. \n",
    "    # For example, if you want to do a sum make sure you type 'sum' rather than 'SUM'.\n",
    "    #\n",
    "\n",
    "    # The possible columns to select from aadhaar data are:\n",
    "    #     1) registrar\n",
    "    #     2) enrolment_agency\n",
    "    #     3) state\n",
    "    #     4) district\n",
    "    #     5) sub_district\n",
    "    #     6) pin_code\n",
    "    #     7) gender\n",
    "    #     8) age\n",
    "    #     9) aadhaar_generated\n",
    "    #     10) enrolment_rejected\n",
    "    #     11) residents_providing_email,\n",
    "    #     12) residents_providing_mobile_number\n",
    "    #\n",
    "    # You can download a copy of the aadhaar data that we are passing \n",
    "    # into this exercise below:\n",
    "    # https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/aadhaar_data.csv\n",
    "        \n",
    "    q = '''\n",
    "    SELECT gender, district, sum(aadhaar_generated) FROM aadhaar_data WHERE age > 50 GROUP BY gender, district;\n",
    "    '''\n",
    "\n",
    "    # Execute your SQL command against the pandas frame\n",
    "    aadhaar_solution = pandasql.sqldf(q.lower(), locals())\n",
    "    \n",
    "    return aadhaar_solution    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_query('aadhaar_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application Programming Interface** API  <br>\n",
    "**Representational State Transfer** REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    url = 'http://blabla'\n",
    "    data = requests.get(url).text\n",
    "    data = json.loads(data)   # Interprets a string and assumes it is a json object\n",
    "    print(type(data))\n",
    "    print(data)\n",
    "    data['artist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    url = 'http://blabla'\n",
    "    data = requests.get(url).text\n",
    "    data = json.loads(data)  \n",
    "   `data['topartists']['artists'][0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Sanity Check\n",
    "pd.read_csv('filename')   # 25/50/75 percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing data: <br>\n",
    "partial deletion: \n",
    "- listwise deletion (exclude a particilar data point from all analysis even if some usuful values were present)\n",
    "- pairwise deletion (exclude a particular case from the analysis for tasks that are not possible with the data at hand)<br><br>\n",
    "imputation: approximation of missing values (includes biases and inaccuracies):\n",
    "- inpute with a mean value\n",
    "- inpute using linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(filename):\n",
    "    baseball = pd.read(filename)\n",
    "    baseball['weight'] = baseball['weight'].fillna(np.mean(baseball['weight']))\n",
    "    return baseball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NY underground weather dataset\n",
    "https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/weather_underground.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasql\n",
    "\n",
    "# Count number of rainy days \n",
    "\n",
    "def num_rainy_days(filename):\n",
    "\n",
    "    weather_data = pd.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT COUNT(*) FROM weather_data WHERE cast(rain as integer)==1;\n",
    "    \"\"\"\n",
    "    \n",
    "    rainy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return rainy_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rainy_days('weather_underground.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the maximum temperature reached depending on if the weather was foggy or not\n",
    "def max_temp_aggregate_by_fog(filename):\n",
    "\n",
    "    weather_data = pd.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT fog, MAX(cast(maxtempi as integer)) FROM weather_data GROUP BY fog ;\n",
    "    \"\"\"\n",
    "    \n",
    "    foggy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return foggy_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_temp_aggregate_by_fog('weather_underground.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_weekend_temperature(filename):\n",
    " \n",
    "    weather_data = pd.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT AVG(cast (meantempi as integer)) FROM weather_data \n",
    "    WHERE cast (strftime('%w', date) as integer) == 0 OR\n",
    "          cast (strftime('%w', date) as integer) == 6\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_temp_weekends = pandasql.sqldf(q.lower(), locals())\n",
    "    return mean_temp_weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_weekend_temperature('weather_underground.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_min_temperature(filename):\n",
    "\n",
    "    weather_data = pd.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT AVG(mintempi) FROM weather_data WHERE cast(rain as integer)==1 AND cast(mintempi as integer)>55\n",
    "    \"\"\"\n",
    "    avg_min_temp_rainy = pandasql.sqldf(q.lower(), locals())\n",
    "    return avg_min_temp_rainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_min_temperature('weather_underground.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turnstile data: http://web.mta.info/developers/data/nyct/turnstile/turnstile_110507.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def fix_turnstile_data(filenames):\n",
    "\n",
    "    for name in filenames:\n",
    "        \n",
    "        with open(name, 'rb') as f:\n",
    "            reader = csv.reader(f, delimiter=' ')\n",
    "\n",
    "            new_name = \"updated_\" + filename\n",
    "        with open(new_name, 'wb') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(someiterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5, 6]\n",
    "a[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 43, 5):\n",
    "    print(i, i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filename = 'turnstile-110528.txt'\n",
    "new_name = \"updated_\" + filename\n",
    "\n",
    "with open(filename, 'rt') as f:\n",
    "    reader = csv.reader(f)\n",
    "    \n",
    "    with open(new_name, 'wt') as f:\n",
    "        writer = csv.writer(f)\n",
    "            \n",
    "        for row in reader:\n",
    "    \n",
    "            for i in range(3, len(row), 5): \n",
    "                updated_row = row[:3] + row[i:i+5]\n",
    "          \n",
    "                writer.writerow(updated_row)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_turnstile_file(filename, output_file):\n",
    "    '''\n",
    "    Write a function that takes the files in the list filenames, which all have the \n",
    "    columns 'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn', and consolidates\n",
    "    them into one file located at output_file.  There should be ONE row with the column\n",
    "    headers, located at the top of the file. The input files do not have column header\n",
    "    rows of their own.\n",
    "    \n",
    "    For example, if file_1 has:\n",
    "    line 1 ...\n",
    "    line 2 ...\n",
    "    \n",
    "    and another file, file_2 has:\n",
    "    line 3 ...\n",
    "    line 4 ...\n",
    "    line 5 ...\n",
    "    \n",
    "    We need to combine file_1 and file_2 into a master_file like below:\n",
    "     'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn'\n",
    "    line 1 ...\n",
    "    line 2 ...\n",
    "    line 3 ...\n",
    "    line 4 ...\n",
    "    line 5 ...\n",
    "    '''\n",
    "    with open(output_file, 'w') as master_file:\n",
    "        master_file.write('C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')\n",
    "        #for filename in filenames:\n",
    "        with open(filename, 'r') as file:\n",
    "            master_file.write(str(file.read()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_master_turnstile_file('updated_turnstile-110528.txt', 'turnstile_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_by_regular(filename):\n",
    "    '''\n",
    "    This function should read the csv file located at filename into a pandas dataframe,\n",
    "    and filter the dataframe to only rows where the 'DESCn' column has the value 'REGULAR'.\n",
    "    \n",
    "    For example, if the pandas dataframe is as follows:\n",
    "    ,C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    1,A002,R051,02-00-00,05-01-11,04:00:00,DOOR,3144335,1088159\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    3,A002,R051,02-00-00,05-01-11,12:00:00,DOOR,3144424,1088231\n",
    "    \n",
    "    The dataframe will look like below after filtering to only rows where DESCn column\n",
    "    has the value 'REGULAR':\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    '''\n",
    "    \n",
    "    turnstile_data = pd.read_csv(filename)\n",
    "    turnstile_data = turnstile_data[turnstile_data['DESCn'] == \"REGULAR\"] \n",
    "   \n",
    "    return turnstile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_by_regular('turnstile_output')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_entries(df):\n",
    "    '''\n",
    "    The data in the MTA Subway Turnstile data reports on the cumulative\n",
    "    number of entries and exits per row.  Assume that you have a dataframe\n",
    "    called df that contains only the rows for a particular turnstile machine\n",
    "    (i.e., unique SCP, C/A, and UNIT).  This function should change\n",
    "    these cumulative entry numbers to a count of entries since the last reading\n",
    "    (i.e., entries since the last row in the dataframe).\n",
    "    \n",
    "    More specifically, you want to do two things:\n",
    "       1) Create a new column called ENTRIESn_hourly\n",
    "       2) Assign to the column the difference between ENTRIESn of the current row \n",
    "          and the previous row. If there is any NaN, fill/replace it with 1.\n",
    "    \n",
    "    You may find the pandas functions shift() and fillna() to be helpful in this exercise.\n",
    "    \n",
    "    Examples of what your dataframe should look like at the end of this exercise:\n",
    "    \n",
    "           C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly\n",
    "    0     A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                1\n",
    "    1     A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23\n",
    "    2     A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18\n",
    "    3     A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71\n",
    "    4     A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170\n",
    "    5     A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214\n",
    "    6     A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87\n",
    "    7     A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10\n",
    "    8     A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36\n",
    "    9     A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153\n",
    "    10    A002  R051  02-00-00  05-02-11  16:00:00  REGULAR   3145337   1088823              243\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    '''\n",
    "    df[\"ENTRIESn_hourly\"] = df[\"ENTRIESn\"] - df[\"ENTRIESn\"].shift(periods=1)\n",
    "    df = df.fillna(1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = get_hourly_entries(df)\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_exits(df):\n",
    "    '''\n",
    "    The data in the MTA Subway Turnstile data reports on the cumulative\n",
    "    number of entries and exits per row.  Assume that you have a dataframe\n",
    "    called df that contains only the rows for a particular turnstile machine\n",
    "    (i.e., unique SCP, C/A, and UNIT).  This function should change\n",
    "    these cumulative exit numbers to a count of exits since the last reading\n",
    "    (i.e., exits since the last row in the dataframe).\n",
    "    \n",
    "    More specifically, you want to do two things:\n",
    "       1) Create a new column called EXITSn_hourly\n",
    "       2) Assign to the column the difference between EXITSn of the current row \n",
    "          and the previous row. If there is any NaN, fill/replace it with 0.\n",
    "    \n",
    "    You may find the pandas functions shift() and fillna() to be helpful in this exercise.\n",
    "    \n",
    "    Example dataframe below:\n",
    "\n",
    "          Unnamed: 0   C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly  EXITSn_hourly\n",
    "    0              0  A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                0              0\n",
    "    1              1  A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23              8\n",
    "    2              2  A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18             18\n",
    "    3              3  A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71             54\n",
    "    4              4  A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170             44\n",
    "    5              5  A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214             42\n",
    "    6              6  A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87             11\n",
    "    7              7  A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10              3\n",
    "    8              8  A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36             89\n",
    "    9              9  A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153            333\n",
    "    '''\n",
    "    \n",
    "    df[\"EXITSn_hourly\"] = df[\"EXITSn\"] - df[\"EXITSn\"].shift(periods=1)\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_hour(time):\n",
    "    '''\n",
    "    Given an input variable time that represents time in the format of:\n",
    "    \"00:00:00\" (hour:minutes:seconds)\n",
    "    \n",
    "    Write a function to extract the hour part from the input variable time\n",
    "    and return it as an integer. For example:\n",
    "        1) if hour is 00, your code should return 0\n",
    "        2) if hour is 01, your code should return 1\n",
    "        3) if hour is 21, your code should return 21\n",
    "        \n",
    "    Please return hour as an integer.\n",
    "    '''\n",
    "    hour = int(time[:2])\n",
    "    return hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def reformat_subway_dates(date):\n",
    "    '''\n",
    "    The dates in our subway data are formatted in the format month-day-year.\n",
    "    The dates in our weather underground data are formatted year-month-day.\n",
    "    \n",
    "    In order to join these two data sets together, we'll want the dates formatted\n",
    "    the same way.  Write a function that takes as its input a date in the MTA Subway\n",
    "    data format, and returns a date in the weather underground format.\n",
    "    \n",
    "    Hint: \n",
    "    There are a couple of useful functions in the datetime library that will\n",
    "    help on this assignment, called strptime and strftime. \n",
    "    More info can be seen here and further in the documentation section:\n",
    "    http://docs.python.org/2/library/datetime.html#datetime.datetime.strptime\n",
    "    '''\n",
    "\n",
    "    date_formatted = datetime.datetime.strptime(date, '%m-%d-%y')\n",
    "    date_formatted.strftime('%Y-%m-%d')\n",
    "    return date_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1993, 3, 30, 0, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reformat_subway_dates('03-30-93')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
